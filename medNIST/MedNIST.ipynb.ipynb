{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "install data\n",
        "\n",
        "https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz"
      ],
      "metadata": {
        "id": "gur_fD4hbBOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install wget\n",
        "import wget\n",
        "import os\n",
        "\n",
        "if os.path.isfile('MedNIST.tar.gz'):\n",
        "  pass\n",
        "else:\n",
        "  wget.download(\"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLiaA_tVcAju",
        "outputId": "f1eb23e2-6f00-41d1-9942-7898e062ddfe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.9/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!  tar -xf \"MedNIST.tar.gz\""
      ],
      "metadata": {
        "id": "hKvk7mj3c4Yq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm \"./MedNIST/README.md\""
      ],
      "metadata": {
        "id": "DpGoIyChgkUH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MedNIST_DATA_DIR = f\"./MedNIST\""
      ],
      "metadata": {
        "id": "S4QZojlbfm0H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages"
      ],
      "metadata": {
        "id": "R5GxuZgKVKqD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BwgvklVdVDiv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy\n",
        "from PIL import Image\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess parameters and constants"
      ],
      "metadata": {
        "id": "LhbxJXC1VWxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_RATIO = 0.2"
      ],
      "metadata": {
        "id": "uiHssCCjV2cN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Code"
      ],
      "metadata": {
        "id": "u3Cfg7g6V20I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(\"./X_train.npy\") and os.path.isfile(\"./Y_train\") and os.path.isfile(\"./X_test.npy\") and os.path.isfile(\"./Y_test.npy\"):\n",
        "        train_x = numpy.load('./X_train.npy')\n",
        "        train_y = numpy.load('./Y_train.npy')\n",
        "        valid_x = numpy.load('./X_test.npy')\n",
        "        valid_y = numpy.load('./Y_test.npy')\n",
        "\n",
        "        train_x = torch.FloatTensor(train_x)\n",
        "        valid_x = torch.FloatTensor(valid_x)\n",
        "        train_y = torch.LongTensor(train_y)\n",
        "        valid_y = torch.LongTensor(valid_y)\n",
        "\n",
        "else:\n",
        "  data_folder_list = os.listdir(MedNIST_DATA_DIR)\n",
        "  dataset_dict = dict()\n",
        "  for category,folder in enumerate(data_folder_list):\n",
        "      dataset_dict[f'{folder}'] = list()\n",
        "      for img in os.listdir(f'{MedNIST_DATA_DIR}/{folder}'):\n",
        "          img_array = numpy.asarray(Image.open(f'{MedNIST_DATA_DIR}/{folder}/{img}'))\n",
        "          dataset_dict[f'{folder}'].append([img_array,category])\n",
        "\n",
        "  tmp_test = list()\n",
        "  tmp_train = list()\n",
        "  \n",
        "  for key in dataset_dict.keys():\n",
        "      tmp_test.append(dataset_dict[key][:int(TEST_RATIO*len(dataset_dict[key]))])\n",
        "      tmp_train.append(dataset_dict[key][int(TEST_RATIO*len(dataset_dict[key])):])\n",
        "\n",
        "  train_x = list()\n",
        "  train_y = list()\n",
        "  valid_x = list()\n",
        "  valid_y = list()\n",
        "\n",
        "  for key in range(6):\n",
        "      for train_data_x, train_data_y in tmp_train[key]:\n",
        "          train_x.append([train_data_x])\n",
        "          train_y.append(train_data_y)\n",
        "\n",
        "      for test_data_x, test_data_y in tmp_test[key]:\n",
        "          valid_x.append([test_data_x])\n",
        "          valid_y.append(test_data_y)\n",
        "\n",
        "  train_x = numpy.asarray(train_x)\n",
        "  train_y = numpy.asarray(train_y)\n",
        "  valid_x = numpy.asarray(valid_x)\n",
        "  valid_y = numpy.asarray(valid_y)\n",
        "\n",
        "  train_x = train_x/255.0\n",
        "  valid_x = valid_x/255.0\n",
        "\n",
        "  train_y = numpy.ravel(train_y)\n",
        "  valid_y = numpy.ravel(valid_y)\n",
        "  \n",
        "  train_index = numpy.arange(len(train_x))\n",
        "  random.Random(6).shuffle(train_index)\n",
        "\n",
        "  train_x = train_x[train_index]\n",
        "  train_y = train_y[train_index]\n",
        "\n",
        "  test_index = numpy.arange(len(valid_x))\n",
        "  random.Random(7).shuffle(test_index)\n",
        "\n",
        "  valid_x = valid_x[test_index]\n",
        "  valid_y = valid_y[test_index]\n",
        "\n",
        "  train_x = torch.FloatTensor(train_x)\n",
        "  valid_x = torch.FloatTensor(valid_x)\n",
        "  train_y = torch.LongTensor(train_y)\n",
        "  valid_y = torch.LongTensor(valid_y)\n",
        "\n",
        "  numpy.save('./X_train.npy',train_x.cpu().numpy())\n",
        "  numpy.save('./Y_train.npy',train_y.cpu().numpy())\n",
        "  numpy.save('./X_test.npy',valid_x.cpu().numpy())\n",
        "  numpy.save('./Y_test.npy',valid_y.cpu().numpy())"
      ],
      "metadata": {
        "id": "g-bmRLGkVo-M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader parameter"
      ],
      "metadata": {
        "id": "yAkiF-JGWJ_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1024"
      ],
      "metadata": {
        "id": "8Iuv7zuzWMsw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Dataloader"
      ],
      "metadata": {
        "id": "g0FDyPtQWCbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torch.utils.data.TensorDataset(train_x, train_y)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "valid_set = torch.utils.data.TensorDataset(valid_x, valid_y)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "5W9SUGmrWawo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Device"
      ],
      "metadata": {
        "id": "4d8LoKHwWx7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "if USE_CUDA:\n",
        "    device = torch.device(f'cuda:0')\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "B482p8blWuW3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Config Model"
      ],
      "metadata": {
        "id": "av4l7714WzX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2d_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Conv2d_Model, self).__init__()\n",
        "        self.convolution_layer1 = nn.Conv2d(1,6,3)\n",
        "        self.convolution_layer2 = nn.Conv2d(6,12,3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dense_layer1 = nn.Linear(14*14*12, 256)\n",
        "        self.dense_layer2 = nn.Linear(256, 32)\n",
        "        self.dense_layer3 = nn.Linear(32, 6)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.convolution_layer1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.convolution_layer2(x))\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.dense_layer1(x))\n",
        "        x = F.relu(self.dense_layer2(x))\n",
        "        x = self.dense_layer3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "e4w-gP7oW5mE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Model object"
      ],
      "metadata": {
        "id": "oG1tTg42Xxm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Conv2d_Model()\n",
        "if USE_CUDA: model.cuda()"
      ],
      "metadata": {
        "id": "sLGpgqyxXl0P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Loss Function and Optimizer "
      ],
      "metadata": {
        "id": "IKBIbCwgXBhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "lYfU3jfcXhcg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters for training session"
      ],
      "metadata": {
        "id": "wrirMyqTYNJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 100\n",
        "PATIENCE_LIMIT = 5\n",
        "CURRENT_PAIENCE = 0\n",
        "STANDARD_VAL_LOSS = 10**9"
      ],
      "metadata": {
        "id": "AYT7ofMJYUWb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "9qDOYMOLX61E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCH):\n",
        "  print(f\"---------------Epoch : {epoch+1}/{EPOCH}--------------------\")\n",
        "  train_loss = 0.0\n",
        "\n",
        "  for train_idx, data in enumerate(train_loader, 0):\n",
        "    optimizer.zero_grad()\n",
        "    print('\\r',f\"training {train_idx+1}/{len(train_loader)}, train_loss: {train_loss:0.4f}\",end=\" \")\n",
        "    inputs, labels = data\n",
        "\n",
        "    outputs = model(inputs.to(device))\n",
        "    loss = criterion(outputs, labels.to(device))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "  print('')\n",
        "  print('\\n')\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  tot_val_loss = 0.0\n",
        "  acc = 0.0\n",
        "    \n",
        "  for val_idx, val_data in enumerate(valid_loader, 0):\n",
        "    print('\\r',f\"validing {val_idx+1}/{len(valid_loader)}, val_loss:{tot_val_loss:0.4f}, val_acc: {acc:0.4}%\", end=\" \")\n",
        "      \n",
        "    val_inputs, val_label = val_data\n",
        "    val_output = model(val_inputs.to(device))\n",
        "    val_loss = criterion(val_output, val_label.to(device))\n",
        "      \n",
        "    prediction = torch.argmax(val_output,1)\n",
        "    tot_val_loss += val_loss.item() \n",
        "\n",
        "    total += val_label.size(0)\n",
        "    correct += (prediction == val_label.to(device)).sum().item()\n",
        "    acc = 100.0*correct/total\n",
        "  print('')\n",
        "  print('\\n')\n",
        "  \n",
        "  if PATIENCE_LIMIT > CURRENT_PAIENCE:\n",
        "\n",
        "    if val_loss < STANDARD_VAL_LOSS:\n",
        "      \n",
        "      STANDARD_VAL_LOSS = val_loss\n",
        "      best_epoch = epoch+1\n",
        "      best_model = model\n",
        "      CURRENT_PAIENCE = 0\n",
        "\n",
        "    else:\n",
        "      CURRENT_PAIENCE += 1\n",
        "  else:break\n",
        "\n",
        "print('')\n",
        "print('\\n')\n",
        "\n",
        "if (epoch+1) != EPOCH:\n",
        "  print(\"Early Stopping ...\")\n",
        "\n",
        "if os.path.isfile('./2D_CNN_model_parameter'):\n",
        "  os.remove('./2D_CNN_model_parameter')\n",
        "\n",
        "torch.save(best_model.state_dict(), './2D_CNN_model_parameter')\n",
        "print(\"================================================\")\n",
        "print(f\"model parameters from epoch {best_epoch} saved!\")\n",
        "print(\"================================================\")\n",
        "print(\"\\n\")\n",
        "print(\".. model train finished\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCBEy9zCX6Cs",
        "outputId": "8eca8bf8-4cf6-4018-b901-8783732c7d67"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Epoch : 1/100--------------------\n",
            " training 47/47, train_loss: 0.0088 \n",
            "\n",
            "\n",
            " validing 12/12, val_loss:0.0225, val_acc: 99.94% \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Early Stopping ...\n",
            "================================================\n",
            "model parameters from epoch 6 saved!\n",
            "================================================\n",
            "\n",
            "\n",
            ".. model train finished\n"
          ]
        }
      ]
    }
  ]
}